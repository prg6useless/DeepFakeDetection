{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeRealDataset(Dataset):\n",
    "    def __init__(self, real_dir, fake_dir, transform=None):\n",
    "        self.real_images = [os.path.join(real_dir, img) for img in os.listdir(real_dir)]\n",
    "        self.fake_images = [os.path.join(fake_dir, img) for img in os.listdir(fake_dir)]\n",
    "        self.images = self.real_images + self.fake_images\n",
    "        self.labels = [0] * len(self.real_images) + [1] * len(self.fake_images)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_frames_dir = \"/teamspace/studios/this_studio/deepfake/dataset/images/real\"\n",
    "fake_frames_dir = \"/teamspace/studios/this_studio/deepfake/dataset/images/fake\"\n",
    "dataset = FakeRealDataset(real_frames_dir, fake_frames_dir, transform=transform)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 512) \n",
    "        self.fc2 = nn.Linear(512, 2)  \n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CustomCNN()\n",
    "model = model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, (3, 224, 224))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from comet_ml import Experiment\n",
    "\n",
    "def train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, num_epochs, device):\n",
    "    experiment = Experiment(\n",
    "        api_key=os.getenv(\"API_KEY\"),\n",
    "        project_name=os.getenv(\"PROJECT_NAME\"),\n",
    "        workspace=os.getenv(\"WORKSPACE\")\n",
    "    )\n",
    "\n",
    "    experiment.log_parameters({\n",
    "        \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "        \"batch_size\": train_loader.batch_size,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"model\": model.__class__.__name__\n",
    "    })\n",
    "\n",
    "    best_accuracy = 0.0\n",
    "    global_step = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  \n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_pbar):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad() \n",
    "            outputs = model(inputs)  \n",
    "            loss = criterion(outputs, targets)  \n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "\n",
    "   \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += targets.size(0)\n",
    "            train_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            step_loss = loss.item()\n",
    "            step_accuracy = 100. * predicted.eq(targets).sum().item() / targets.size(0)\n",
    "            experiment.log_metric(\"train_step_loss\", step_loss, step=global_step)\n",
    "            experiment.log_metric(\"train_step_accuracy\", step_accuracy, step=global_step)\n",
    "\n",
    "            train_pbar.set_postfix({'Loss': train_loss / (batch_idx + 1), 'Acc': 100. * train_correct / train_total})\n",
    "            global_step += 1\n",
    "\n",
    "        train_accuracy = 100. * train_correct / train_total\n",
    "        experiment.log_metric(\"train_epoch_loss\", train_loss / len(train_loader), step=epoch)\n",
    "        experiment.log_metric(\"train_epoch_accuracy\", train_accuracy, step=epoch)\n",
    "\n",
    "        model.eval()  \n",
    "        test_loss = 0.0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        with torch.no_grad():\n",
    "            test_pbar = tqdm(test_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Test]')\n",
    "\n",
    "            for batch_idx, (inputs, targets) in enumerate(test_pbar):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                test_total += targets.size(0)\n",
    "                test_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                step_loss = loss.item()\n",
    "                step_accuracy = 100. * predicted.eq(targets).sum().item() / targets.size(0)\n",
    "                experiment.log_metric(\"test_step_loss\", step_loss, step=global_step)\n",
    "                experiment.log_metric(\"test_step_accuracy\", step_accuracy, step=global_step)\n",
    "\n",
    "                test_pbar.set_postfix({'Loss': test_loss / (batch_idx + 1), 'Acc': 100. * test_correct / test_total})\n",
    "\n",
    "        test_accuracy = 100. * test_correct / test_total\n",
    "        experiment.log_metric(\"test_epoch_loss\", test_loss / len(test_loader), step=epoch)\n",
    "        experiment.log_metric(\"test_epoch_accuracy\", test_accuracy, step=epoch)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'Train Loss: {train_loss/len(train_loader):.4f}, Train Acc: {train_accuracy:.2f}%')\n",
    "        print(f'Test Loss: {test_loss/len(test_loader):.4f}, Test Acc: {test_accuracy:.2f}%')\n",
    "\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            torch.save(model.state_dict(), 'best_model_cnn.pth')\n",
    "            print(f'Best model saved with accuracy: {best_accuracy:.2f}%')\n",
    "            experiment.log_model(\"best_model\", 'best_model.pth')\n",
    "\n",
    "        print()\n",
    "\n",
    "    experiment.end()\n",
    "\n",
    "num_epochs = 15\n",
    "train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, num_epochs, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusemachines",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
